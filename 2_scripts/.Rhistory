#Install the package, uncomment the next line if necessary
# install.packages("rtweet")
#Load library
library(rtweet)
#Load library
library(tidyverse)
token = get_token()
d = search_tweets(
q = "Universität OR Basel",
n = 10,
lang = "de",
geocode = "47.05,8.27,100km",
include_rts = FALSE,
type = "recent",
token = token
)
#Install the package, uncomment the next line if necessary
# install.packages("rtweet")
#Load library
library(rtweet)
#Load library
library(tidyverse)
token = get_token()
d = search_tweets(
q = "Universität OR Basel",
n = 10,
lang = "de",
geocode = "47.05,8.27,100km",
include_rts = FALSE,
type = "recent",
token = token
)
d = search_tweets(
q = "",
n = 10000,
lang = "de",
geocode = "47.05,8.27,100km",
include_rts = FALSE,
type = "recent",
token = token
)
#collapse the dataframe
d_collapsed <- as.data.frame(apply(d,2,as.character))
#write filename from date
date = Sys.Date()
filename = paste(c("../3_tweets/", date , ".csv"), collapse = "", sep = " ")
#write csv
write_csv(d_collapsed, file = filename)
d_cut = d %>% select(user_id, status_id, screen_name, text, favorite_count, retweet_count, reply_count)
d_cut
Packages <- c("sentimentr", "tidytext", "lubridate")
lapply(Packages, library, character.only = TRUE)
d = d %>% filter(is_quote == FALSE, is_retweet ==FALSE)
# load sentiment files
negativ <- read.table("../../Lexica/Deutsch/SentiWS_v2.0_Negative.txt", fill = TRUE,encoding = "UTF-8")
# load sentiment files
negativ <- read.table("../1_data/Lexica/Deutsch/SentiWS_v2.0_Negative.txt", fill = TRUE,encoding = "UTF-8")
positiv <- read.table("../1_data/Lexica/Deutsch/SentiWS_v2.0_Positive.txt", fill = TRUE,encoding = "UTF-8")
#delete the NN stuff
negativ = separate(data = negativ, col = V1, sep =  "[|]", into = "V1")
positiv = separate(data = positiv, col = V1, sep =  "[|]", into = "V1")
#split into single words
einzelworte_negativ <- strsplit(as.character(negativ$V3), split =",")
einzelworteframe_negativ <- as.data.frame(unlist(einzelworte_negativ))
einzelworte_positiv <- strsplit(as.character(positiv$V3), split =",")
einzelworteframe_positiv <- as.data.frame(unlist(einzelworte_positiv))
#takes the number of words and creates a data frame only with the sentiment scores as many times as the word inflection occurs.
number_words <- summary(einzelworte_negativ)
sentiment_score <- NULL
for (i in 1:1827) {
j <- 0
while (j < as.numeric(number_words[i])) {
sentiment_score <- rbind(sentiment_score, negativ[i,2])
j <- j+1
}
}
number_words <- summary(einzelworte_positiv)
sentiment_score <- NULL
for (i in 1:1645) {
j <- 0
while (j < as.numeric(number_words[i])) {
sentiment_score <- rbind(sentiment_score, positiv[i,2])
j <- j+1
}
}
#bind the sentiment score with the words
new_negativ <- cbind(as.character(einzelworteframe_negativ[,1]), sentiment_score)
new_negativ <- rbind(negativ[,1:2], new_negativ)
new_positiv <- cbind(as.character(einzelworteframe_positiv[,1]), sentiment_score)
new_positiv <- rbind(positiv[,1:2], new_positiv)
lexicon = bind_rows(new_positiv, new_negativ)
lexicon = lexicon %>% select(V1, V2) %>% rename(polarity = V2, word = V1) %>% mutate_all(.funs=tolower)
lexicon$polarity = as.numeric(lexicon$polarity)
lexikey = as_key(lexicon)
lexikey
#Tokenize corpus
sentence_tbl = unnest_tokens(d_cut, input = "text", token = "sentences", to_lower = TRUE, output = "sentence")
#neg
sentiment("Dieser Satz ist negativ und schädlich", polarity_dt = lexikey)
#pos
sentiment("Dieser positive Satz ist gelungen", polarity_dt = lexikey)
#mixed
sentiment("Dieser Satz ist unnötig, schädlich, schwach aber gelungen", polarity_dt = lexikey)
#sentiment analyses by
sentiment = sentiment_by(sentence_tbl$sentence, by = sentence_tbl$status_id, polarity_dt = lexikey)
#Join the dataframes of the sentiment analysis and the tokens
sentence_tbl <- inner_join(y = sentiment,x = sentence_tbl)
#Arrange
sentence_tbl = sentence_tbl %>% arrange(desc(favorite_count))
#summarise with the engagement variables
tweet_tbl = sentence_tbl %>% select(ave_sentiment, status_id, favorite_count, retweet_count) %>% group_by(status_id) %>%
summarise(mean_affect = mean(ave_sentiment),
favorite_count = mean(favorite_count),
retweet_count = mean(retweet_count))
hist(tweet_tbl$mean_affect)
quantile(tweet_tbl$mean_affect)
tweet_tbl = tweet_tbl %>% mutate(
intensity = abs(mean_affect),
valence = case_when(
mean_affect > 0 ~ "positive",
mean_affect == 0 ~ "neutral",
mean_affect < 0 ~ "negative"
),
valence = as.factor(valence)
)
tweet_tbl = tweet_tbl %>% mutate(
valence_5 = case_when(
mean_affect > 0.1 ~ "very positive",
mean_affect > 0 & mean_affect < 0.1 ~ "positive",
mean_affect == 0 ~ "neutral",
mean_affect < 0 & mean_affect > -0.1 ~ "negative",
mean_affect < -0.1 ~ "very negative"
),
valence_5 = as.factor(valence_5)
)
# table(tweet_tbl$valence_5)
#relevel
tweet_tbl$valence_5 = ordered(tweet_tbl$valence_5 , levels = c("very negative", "negative","neutral","positive","very positive"))
tweet_tbl %>% ggplot(aes(intensity)) + geom_histogram() +theme_minimal()
tweet_tbl %>% ggplot(aes(valence)) + geom_bar() +theme_minimal()
tweet_tbl %>% ggplot(aes(valence_5)) + geom_bar() +theme_minimal()
tweet_tbl %>% ggplot(aes(favorite_count)) + geom_histogram() +theme_minimal()
tweets = tweet_tbl
### analyses with log(views_youtube) or poisson ###
tilt_theme <- theme(axis.text.x=element_text(angle=45, hjust=1))
# normal
affect_normal <- ggplot(tweets, aes(mean_affect, favorite_count)) +
geom_point() +labs(title= "") + tilt_theme
affect_normal
# using log(views_youtube)
affect <- ggplot(tweets, aes(mean_affect, log(favorite_count))) +
geom_point() +labs(title= "Log(favorite_count) by avg. sentiment") + tilt_theme +
labs(x = "average sentiment of each Tweet", y = "log(Likes)")
affect
# poisson regression
poiss_aff <- glm(favorite_count ~ mean_affect + intensity + valence_5, family = "poisson", data = tweets)
summary(poiss_aff)
prediction = predict(poiss_aff)
# add predicted log(views_youtube) to tweets
tweets <- tweets %>% mutate(pred_affect = prediction)
# plot the points (actual observations), regression line
plot_affect = ggplot(tweets, aes(intensity,log(favorite_count))) +
geom_point() +
geom_smooth(aes(intensity, pred_affect)) +
labs(title= "", x = "average sentiment of tweet", y = "Log(number of favs)")
plot_affect
tweets %>% ggplot(aes(x = valence_5, y = intensity)) + geom_boxplot()
tweets %>% ggplot(aes(x = valence_5, y = intensity)) + geom_boxplot()
# calculate sentiment var
token_tbl = d_cut %>%
unnest_tokens(input = text,  output = "word",
to_lower = TRUE) %>%
left_join(lexikey %>% rename(value = y),
by = c("word" = "x")) %>%
group_by(status_id) %>%
summarize(affect = mean(!is.na(value)),
avg_sent = mean(value, na.rm=T),
posemo = mean(value[value>0], na.rm=T),
negemo = mean(value[value<0], na.rm=T))
tweets2 = d %>% left_join(token_tbl, by = "status_id")
# using log(views_youtube)
affect <- ggplot(tweets2, aes(affect, log(favorite_count))) +
geom_point() +labs(title= "Log(favorite count) by % of affect words") + tilt_theme +
labs(x = "% of affect words in a Tweet", y = "log(favorite count)")
affect
# poisson regression
poiss_aff <- glm(favorite_count ~ affect, family = "poisson", data = tweets2)
summary(poiss_aff)
prediction = predict(poiss_aff)
# add predicted log(views_youtube) to tweets
tweets2 <- tweets2 %>% mutate(pred_affect = prediction)
# plot the points (actual observations), regression line
plot_affect <- ggplot(tweets2, aes(affect,log(favorite_count))) +
geom_point() +
geom_smooth(aes(affect, pred_affect)) +
labs(title= "Log(favorite_count) by % of affect words", x = "% of affect words in a tweet", y = "log(favorite_count)")
plot_affect
(poiss_aff)
summary(poiss_aff)
# poisson regression of positive affect
poiss_pos <- glm(favorite_count ~ posemo, family = "poisson", data = tweets2)
summary(poiss_pos)
prediction = predict(poiss_pos)
# add predicted log(views_youtube) to talks
tweets2 <- tweets2 %>% mutate(pred_pos = prediction)
summary(poiss_pos)
prediction = predict(poiss_pos)
# add predicted log(views_youtube) to talks
tweets2 <- tweets2 %>% mutate(pred_pos = prediction)
tweets2 = d %>% left_join(token_tbl, by = "status_id") %>% mutate_all(~replace(., is.na(.), 0))
# calculate sentiment var
token_tbl = d_cut %>%
unnest_tokens(input = text,  output = "word",
to_lower = TRUE) %>%
left_join(lexikey %>% rename(value = y),
by = c("word" = "x")) %>%
group_by(status_id) %>%
summarize(affect = mean(!is.na(value)),
avg_sent = mean(value, na.rm=T),
posemo = mean(value[value>0], na.rm=T),
negemo = mean(value[value<0], na.rm=T)) %>%
mutate_all(~replace(., is.na(.), 0))
tweets2 = d %>% left_join(token_tbl, by = "status_id")
tweets2
# using log(views_youtube)
affect <- ggplot(tweets2, aes(affect, log(favorite_count))) +
geom_point() +labs(title= "Log(favorite count) by % of affect words") + tilt_theme +
labs(x = "% of affect words in a Tweet", y = "log(favorite count)")
affect
# poisson regression
poiss_aff <- glm(favorite_count ~ affect, family = "poisson", data = tweets2)
summary(poiss_aff)
prediction = predict(poiss_aff)
# add predicted log(views_youtube) to tweets
tweets2 <- tweets2 %>% mutate(pred_affect = prediction)
# plot the points (actual observations), regression line
plot_affect <- ggplot(tweets2, aes(affect,log(favorite_count))) +
geom_point() +
geom_smooth(aes(affect, pred_affect)) +
labs(title= "Log(favorite_count) by % of affect words", x = "% of affect words in a tweet", y = "log(favorite_count)")
plot_affect
# poisson regression of positive affect
poiss_pos <- glm(favorite_count ~ posemo, family = "poisson", data = tweets2)
summary(poiss_pos)
prediction = predict(poiss_pos)
# add predicted log(views_youtube) to talks
tweets2 <- tweets2 %>% mutate(pred_pos = prediction)
# posemo plot the points (actual observations), regression line
plot_posemo <- ggplot(tweets2, aes(posemo, log(favorite_count))) +
geom_point() +
geom_smooth(aes(posemo, pred_pos)) +
labs(title= "Log(favorite_count) by % of positive affect words", x = "% of positive affect words in a tweet", y = "log(favorite_count)")
plot_posemo
# poisson regression of positive affect
poiss_neg <- glm(favorite_count ~ negemo, family = "poisson", data = tweets2)
summary(poiss_neg)
prediction = predict(poiss_neg)
# add predicted log(views_youtube) to talks
tweets2 <- tweets2 %>% mutate(pred_neg = prediction)
# posemo plot the points (actual observations), regression line
plot_negemo <- ggplot(tweets2, aes(negemo, log(favorite_count))) +
geom_point() +
geom_smooth(aes(negemo, pred_neg)) +
labs(title= "Log(favorite_count) by % of positive affect words", x = "% of positive affect words in a tweet", y = "log(favorite_count)")
plot_negemo
token = get_token()
d = search_tweets(
q = "Roger OR Federer",
n = 10,
lang = "en",
geocode = "47.05,8.27,100km",
include_rts = FALSE,
type = "recent",
token = token
)
View(d)
d = search_tweets(
q = "",
n = 10000,
lang = "en",
geocode = "",
include_rts = FALSE,
type = "recent",
token = token
)
#collapse the dataframe
d_collapsed <- as.data.frame(apply(d,2,as.character))
#write filename from date
date = Sys.Date()
filename = paste(c("../3_tweets/", date , ".csv"), collapse = "", sep = " ")
#write csv
write_csv(d_collapsed, file = filename)
View(d)
d_cut = d %>% select(user_id, status_id, screen_name, text, favorite_count, retweet_count, reply_count)
d_cut
Packages <- c("sentimentr", "tidytext", "lubridate")
lapply(Packages, library, character.only = TRUE)
d = d %>% filter(is_quote == FALSE, is_retweet ==FALSE)
Packages <- c("sentimentr", "tidytext", "lubridate", "lexicon")
lapply(Packages, library, character.only = TRUE)
library(lexicon)
lexikey = hash_sentiment_sentiword
lexikey
lexikey = hash_sentiment_sentiword
lexikey
#Tokenize corpus
sentence_tbl = unnest_tokens(d_cut, input = "text", token = "sentences", to_lower = TRUE, output = "sentence")
View(lexikey)
#neg
sentiment("This sentence evokes angriness", polarity_dt = lexikey)
#pos
sentiment("This sentence is excellent", polarity_dt = lexikey)
#mixed
sentiment("This sentence is excellent and evokes angriness", polarity_dt = lexikey)
#sentiment analyses by
sentiment = sentiment_by(sentence_tbl$sentence, by = sentence_tbl$status_id, polarity_dt = lexikey)
#Join the dataframes of the sentiment analysis and the tokens
sentence_tbl <- inner_join(y = sentiment,x = sentence_tbl)
#Arrange
sentence_tbl = sentence_tbl %>% arrange(desc(favorite_count))
#summarise with the engagement variables
tweet_tbl = sentence_tbl %>% select(ave_sentiment, status_id, favorite_count, retweet_count) %>% group_by(status_id) %>%
summarise(mean_affect = mean(ave_sentiment),
favorite_count = mean(favorite_count),
retweet_count = mean(retweet_count))
hist(tweet_tbl$mean_affect)
quantile(tweet_tbl$mean_affect)
tweet_tbl = tweet_tbl %>% mutate(
intensity = abs(mean_affect),
valence = case_when(
mean_affect > 0 ~ "positive",
mean_affect == 0 ~ "neutral",
mean_affect < 0 ~ "negative"
),
valence = as.factor(valence)
)
tweet_tbl = tweet_tbl %>% mutate(
valence_5 = case_when(
mean_affect > 0.1 ~ "very positive",
mean_affect > 0 & mean_affect < 0.1 ~ "positive",
mean_affect == 0 ~ "neutral",
mean_affect < 0 & mean_affect > -0.1 ~ "negative",
mean_affect < -0.1 ~ "very negative"
),
valence_5 = as.factor(valence_5)
)
# table(tweet_tbl$valence_5)
#relevel
tweet_tbl$valence_5 = ordered(tweet_tbl$valence_5 , levels = c("very negative", "negative","neutral","positive","very positive"))
tweet_tbl %>% ggplot(aes(intensity)) + geom_histogram() +theme_minimal()
tweet_tbl %>% ggplot(aes(valence)) + geom_bar() +theme_minimal()
tweet_tbl %>% ggplot(aes(valence_5)) + geom_bar() +theme_minimal()
tweet_tbl
table(tweet_tbl$valence_5)
tweet_tbl = tweet_tbl %>% mutate(
valence_5 = case_when(
mean_affect > 0.1 ~ "very positive",
mean_affect > 0 & mean_affect < 0.1 ~ "positive",
mean_affect == 0 ~ "neutral",
mean_affect < 0 & mean_affect > -0.1 ~ "negative",
mean_affect < -0.1 ~ "very negative"
),
valence_5 = as.factor(valence_5)
)
# table(tweet_tbl$valence_5)
#relevel
tweet_tbl$valence_5 = ordered(tweet_tbl$valence_5 , levels = c("very negative", "negative","neutral","positive","very positive"))
tweet_tbl %>% ggplot(aes(intensity)) + geom_histogram() +theme_minimal()
tweet_tbl %>% ggplot(aes(valence)) + geom_bar() +theme_minimal()
tweet_tbl %>% ggplot(aes(valence_5)) + geom_bar() +theme_minimal()
tweet_tbl %>% ggplot(aes(favorite_count)) + geom_histogram() +theme_minimal()
tweets = tweet_tbl
### analyses with log(views_youtube) or poisson ###
tilt_theme <- theme(axis.text.x=element_text(angle=45, hjust=1))
# normal
affect_normal <- ggplot(tweets, aes(mean_affect, favorite_count)) +
geom_point() +labs(title= "") + tilt_theme
affect_normal
# using log(views_youtube)
affect <- ggplot(tweets, aes(mean_affect, log(favorite_count))) +
geom_point() +labs(title= "Log(favorite_count) by avg. sentiment") + tilt_theme +
labs(x = "average sentiment of each Tweet", y = "log(Likes)")
affect
# poisson regression
poiss_aff <- glm(favorite_count ~ mean_affect + intensity + valence_5, family = "poisson", data = tweets)
summary(poiss_aff)
prediction = predict(poiss_aff)
# add predicted log(views_youtube) to tweets
tweets <- tweets %>% mutate(pred_affect = prediction)
# plot the points (actual observations), regression line
plot_affect = ggplot(tweets, aes(intensity,log(favorite_count))) +
geom_point() +
geom_smooth(aes(intensity, pred_affect)) +
labs(title= "", x = "average sentiment of tweet", y = "Log(number of favs)")
plot_affect
# poisson regression
poiss_aff <- glm(favorite_count ~ mean_affect + intensity + valence_5, family = "poisson", data = tweets)
summary(poiss_aff)
prediction = predict(poiss_aff)
# add predicted log(views_youtube) to tweets
tweets <- tweets %>% mutate(pred_affect = prediction)
# poisson regression
poiss_aff <- glm(favorite_count ~ mean_affect + intensity + valence_5, family = "poisson", data = tweets)
summary(poiss_aff)
prediction = predict(poiss_aff)
# add predicted log(views_youtube) to tweets
tweets <- tweets %>% mutate(pred_affect = prediction)
tweet_tbl$valence_5
table(tweet_tbl$valence)
table(tweet_tbl$valence_5)
tweet_tbl$mean_affect
tweet_tbl %>%  select(mean_affect) %>% filter(is.na(mean_affect))
tweet_tbl %>%  select(mean_affect) %>% filter(is.na(mean_affect))
tweet_tbl %>%  select(mean_affect) %>% filter(is.na(mean_affect))
tweet_tbl %>%  select(mean_affect) %>% filter(!is.na(mean_affect))
tweet_tbl %>%  select(mean_affect)
tweet_tbl %>%  select(intensity)
tweet_tbl %>%  select(intensity) %>% filter(!is.na(intensity))
tweet_tbl %>%  select(favorite_count) %>% filter(!is.na(favorite_count))
tweet_tbl %>%  select(favorite_count)
# poisson regression
poiss_aff <- glm(favorite_count ~ mean_affect + intensity + valence_5, family = "poisson", data = tweets)
summary(poiss_aff)
poiss_aff
# plot the points (actual observations), regression line
plot_affect = ggplot(tweets, aes(intensity,log(favorite_count))) +
geom_point() +
geom_smooth(aes(intensity, pred_affect)) +
labs(title= "", x = "average sentiment of tweet", y = "Log(number of favs)")
plot_affect
sum(is.na(tweets))
tweets = tweet_tbl %>% na.rm(tweet_tbl)
tweets = tweet_tbl %>% na.omit(tweet_tbl)
tweets = tweet_tbl %>% na.omit(tweet_tbl)
### analyses with log(views_youtube) or poisson ###
tilt_theme <- theme(axis.text.x=element_text(angle=45, hjust=1))
# normal
affect_normal <- ggplot(tweets, aes(mean_affect, favorite_count)) +
geom_point() +labs(title= "") + tilt_theme
affect_normal
# using log(views_youtube)
affect <- ggplot(tweets, aes(mean_affect, log(favorite_count))) +
geom_point() +labs(title= "Log(favorite_count) by avg. sentiment") + tilt_theme +
labs(x = "average sentiment of each Tweet", y = "log(Likes)")
affect
# poisson regression
poiss_aff <- glm(favorite_count ~ mean_affect + intensity + valence_5, family = "poisson", data = tweets)
summary(poiss_aff)
prediction = predict(poiss_aff)
# add predicted log(views_youtube) to tweets
tweets <- tweets %>% mutate(pred_affect = prediction)
# plot the points (actual observations), regression line
plot_affect = ggplot(tweets, aes(intensity,log(favorite_count))) +
geom_point() +
geom_smooth(aes(intensity, pred_affect)) +
labs(title= "", x = "average sentiment of tweet", y = "Log(number of favs)")
plot_affect
tweets %>% ggplot(aes(x = valence_5, y = intensity)) + geom_boxplot()
# calculate sentiment var
token_tbl = d_cut %>%
unnest_tokens(input = text,  output = "word",
to_lower = TRUE) %>%
left_join(lexikey %>% rename(value = y),
by = c("word" = "x")) %>%
group_by(status_id) %>%
summarize(affect = mean(!is.na(value)),
avg_sent = mean(value, na.rm=T),
posemo = mean(value[value>0], na.rm=T),
negemo = mean(value[value<0], na.rm=T)) %>%
mutate_all(~replace(., is.na(.), 0))
tweets2 = d %>% left_join(token_tbl, by = "status_id")
# using log(views_youtube)
affect <- ggplot(tweets2, aes(affect, log(favorite_count))) +
geom_point() +labs(title= "Log(favorite count) by % of affect words") + tilt_theme +
labs(x = "% of affect words in a Tweet", y = "log(favorite count)")
affect
# poisson regression
poiss_aff <- glm(favorite_count ~ affect, family = "poisson", data = tweets2)
summary(poiss_aff)
prediction = predict(poiss_aff)
# add predicted log(views_youtube) to tweets
tweets2 <- tweets2 %>% mutate(pred_affect = prediction)
# plot the points (actual observations), regression line
plot_affect <- ggplot(tweets2, aes(affect,log(favorite_count))) +
geom_point() +
geom_smooth(aes(affect, pred_affect)) +
labs(title= "Log(favorite_count) by % of affect words", x = "% of affect words in a tweet", y = "log(favorite_count)")
plot_affect
# poisson regression of positive affect
poiss_pos <- glm(favorite_count ~ posemo, family = "poisson", data = tweets2)
summary(poiss_pos)
prediction = predict(poiss_pos)
# add predicted log(views_youtube) to talks
tweets2 <- tweets2 %>% mutate(pred_pos = prediction)
# posemo plot the points (actual observations), regression line
plot_posemo <- ggplot(tweets2, aes(posemo, log(favorite_count))) +
geom_point() +
geom_smooth(aes(posemo, pred_pos)) +
labs(title= "Log(favorite_count) by % of positive affect words", x = "% of positive affect words in a tweet", y = "log(favorite_count)")
plot_posemo
# poisson regression of positive affect
poiss_neg <- glm(favorite_count ~ negemo, family = "poisson", data = tweets2)
summary(poiss_neg)
prediction = predict(poiss_neg)
# add predicted log(views_youtube) to talks
tweets2 <- tweets2 %>% mutate(pred_neg = prediction)
# posemo plot the points (actual observations), regression line
plot_negemo <- ggplot(tweets2, aes(negemo, log(favorite_count))) +
geom_point() +
geom_smooth(aes(negemo, pred_neg)) +
labs(title= "Log(favorite_count) by % of negative affect words", x = "% of negative affect words in a tweet", y = "log(favorite_count)")
plot_negemo
